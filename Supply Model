#%%

import pandas as pd

import os
from dfply import *
from scipy.optimize import curve_fit
from scipy.stats import pearsonr
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import numpy as np
from sklearn import linear_model
from sklearn.datasets import make_classification
import seaborn as sns
sns.set()
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import sklearn.metrics as metrics
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error
from math import sqrt

##Lecture du tableau
#set working directory

os.chdir("C:\\Users\\plego\\Documents\\IN104")
data = pd.ExcelFile('storage_data.xlsx')
sheet_name = data.sheet_names

data = pd.read_excel('storage_data.xlsx', sheet_name = None)

for i in sheet_name :
    data[i] = data[i].drop(['status','workingGasVolume','injectionCapacity','withdrawalCapacity','info'],axis=1)
    data[i]['netWithdrawal']=data[i]['withdrawal'] - data[i]['injection']
    data[i]['Net Withdrawal_binary'] = [0 if wd <=0 else 1 for wd in    data[i]['netWithdrawal']]
    data[i]['Lagged_NW']=0
    for j in range(1,(data[i].shape)[0]-1) :
        data[i].loc[j,'Lagged_NW'] = data[i].loc[j-1,'netWithdrawal']

    data[i]['FSW1'] = [max(s-45,0) for s in data[i]['full']]
    data[i]['FSW2'] = [max(45-s,0) for s in data[i]['full']]

    data[i] = data[i].drop(['gasInStorage','full','trend','injection','withdrawal'],axis=1)
    #print("\n\n",i,"\n")
    #print(data[i].head())

price = pd.read_csv("price_data.csv",sep=";")
price = price >> mutate(Date = pd.to_datetime(price['Date'],format="%d/%m/%Y"))
price = price.rename(columns = {'Date':'gasDayStartedOn'})


##Logistic Regression



for i in sheet_name :

    data[i]=pd.merge(data[i],price,on='gasDayStartedOn')
    X=data[i].loc[:,'Lagged_NW':'SAS_NBP']
    Y=data[i].loc[:,'Net Withdrawal_binary']
print(Y.head())
print(X.head())

#Classification
x_train, x_test, y_train, y_test = train_test_split(X,Y, random_state=1)
lr = LogisticRegression()
lr.fit(x_train, y_train)
print(lr.coef_)
print(lr.intercept_)

y_pred = lr.predict(x_test)
#cm=confusion_matrix(y_test, y_pred)


probs=lr.predict_proba(x_test)[:,1]


Logistic_Regression = {'recall': metrics.recall_score(y_test, y_pred), 'neg_recall': cm[1,1]/(cm[0,1] + cm[1,1]), 'confusion': cm, 'precision': metrics.precision_score(y_test, y_pred), 'neg_precision':cm[1,1]/cm.sum(axis=1)[1], 'roc': metrics.roc_auc_score(y_test, probs),'class_mod': lr.coef_}




##Random Forest
# Create the model with 100 trees

x_train,x_test,y_train,y_test = train_test_split(X,Y,random_state=1)
clf = RandomForestClassifier(100)
clf.fit(x_train,y_train)
y_pred=clf.predict(x_test)

#cm = confusion_matrix(y_test,y_pred)

probs=clf.predict_proba(x_test)[:,1]
print('Accuracy: ',metrics.accuracy_score(y_test, y_pred))

Random_Forest = {'recall': metrics.recall_score(y_test, y_pred), 'neg_recall': cm[1,1]/(cm[0,1] + cm[1,1]), 'confusion': confusion_matrix, 'precision': metrics.precision_score(y_test, y_pred), 'neg_precision':cm[1,1]/cm.sum(axis=1)[1], 'roc': metrics.roc_auc_score(y_test, probs),'class_mod': lr.coef_}


##Choix de la meilleure methode

print('precision LR:',Logistic_Regression['precision'])
print('precision RF:',Random_Forest['precision'])

#%%Linear Regression
for i in sheet_name :

    data[i]=pd.merge(data[i],price,on='gasDayStartedOn')
    X=data[i].loc[:,'Lagged_NW':'SAS_NBP']
    Y=data[i].loc[:,'netWithdrawal']
print(Y.head())
print(X.head())


x_train, x_test, y_train, y_test = train_test_split(X,Y, random_state=1)
lr = LinearRegression()
lr.fit(x_train, y_train)
print(lr.coef_)
print(lr.intercept_)
rmse=sqrt(mean_squared_error(y_test,y_pred))
nrmse=rmse/(max(y_test)-min(y_test))
nrmse=rmse/np.average(y_test)
corr=pearsonr(y_test,y_pred)


Linear_Regression = {'r2': metrics.r2_score(y_test, y_pred), 'rmse': rmse, 'nrmse': nrmse, 'anrmse': anrmse, 'cor': corr, 'l_reg': lr}

##Retrieving
model = {'regression': Linear_Regression, 'classification': Logistic_Regression}
import pickle
filename = 'finalized_model.sav'
pickle.dump(model, open(filename, 'wb'))


